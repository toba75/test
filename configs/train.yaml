# StockGPT Training Configuration

# Model architecture
model:
  vocab_size: 402
  seq_len: 256
  d_model: 128
  n_layers: 4
  n_heads: 4
  dropout: 0.2

# Training parameters
train:
  batch_size: 64
  num_steps: 10000
  learning_rate: 0.0003
  warmup_steps: 500
  weight_decay: 0.01
  grad_clip: 1.0
  log_interval: 100
  eval_interval: 500
  save_interval: 1000
  use_amp: true
  seed: 42

# Data configuration
data:
  data_path: ~/stockGPT/data
  prepared_path: null
  returns_output: null
  train_start: "1926-01-01"
  train_end: "2000-12-31"
  val_start: "1991-01-01"
  val_end: "2000-12-31"
  test_start: "2001-01-01"
  test_end: "2023-12-31"

# Output paths
output:
  checkpoint_dir: outputs/checkpoints
  log_dir: outputs/logs
  mlflow_uri: file:./mlruns
  experiment_name: stockgpt
